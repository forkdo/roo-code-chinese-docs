"use strict";(globalThis.webpackChunkdocs_new=globalThis.webpackChunkdocs_new||[]).push([[86004],{18064(e,o,n){n.r(o),n.d(o,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>i,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"update-notes/v3.32","title":"Roo Code 3.32 Release Notes (2025-11-14)","description":"Combined notes for Roo Code 3.32, including GPT-5.1 model support, OpenAI Responses prompt caching, and reliability fixes for OpenAI Native and native tools.","source":"@site/docs/update-notes/v3.32.mdx","sourceDirName":"update-notes","slug":"/update-notes/v3.32","permalink":"/update-notes/v3.32","draft":false,"unlisted":false,"editUrl":"https://github.com/RooCodeInc/Roo-Code-Docs/edit/main/docs/update-notes/v3.32.mdx","tags":[],"version":"current","lastUpdatedAt":1763175252000,"frontMatter":{"description":"Combined notes for Roo Code 3.32, including GPT-5.1 model support, OpenAI Responses prompt caching, and reliability fixes for OpenAI Native and native tools.","keywords":["roo code 3.32","release notes","gpt-5.1","openai prompt caching","bug fixes"],"image":"/img/v3.32.0/v3.32.0.png"},"sidebar":"tutorialSidebar","previous":{"title":"3.33.0","permalink":"/update-notes/v3.33.0"},"next":{"title":"3.32.1","permalink":"/update-notes/v3.32.1"}}');var t=n(74848),r=n(28453);const i={description:"Combined notes for Roo Code 3.32, including GPT-5.1 model support, OpenAI Responses prompt caching, and reliability fixes for OpenAI Native and native tools.",keywords:["roo code 3.32","release notes","gpt-5.1","openai prompt caching","bug fixes"],image:"/img/v3.32.0/v3.32.0.png"},a="Roo Code 3.32 Release Notes (2025-11-14)",l={},d=[{value:"GPT-5.1 models and OpenAI prompt caching",id:"gpt-51-models-and-openai-prompt-caching",level:2},{value:"Bug Fixes",id:"bug-fixes",level:2}];function c(e){const o={a:"a",br:"br",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(o.header,{children:(0,t.jsx)(o.h1,{id:"roo-code-332-release-notes-2025-11-14",children:"Roo Code 3.32 Release Notes (2025-11-14)"})}),"\n",(0,t.jsx)(o.p,{children:"Roo Code 3.32 combines GPT-5.1 model support and OpenAI Responses prompt caching with reliability fixes for OpenAI Native and native tool protocol."}),"\n",(0,t.jsx)("img",{src:"/img/v3.32.0/v3.32.0.png",alt:"Roo Code v3.32 Release",width:"600"}),"\n",(0,t.jsx)(o.h2,{id:"gpt-51-models-and-openai-prompt-caching",children:"GPT-5.1 models and OpenAI prompt caching"}),"\n",(0,t.jsxs)(o.ul,{children:["\n",(0,t.jsxs)(o.li,{children:[(0,t.jsx)(o.strong,{children:"GPT-5.1 in Roo Code"})," (",(0,t.jsx)(o.a,{href:"https://github.com/RooCodeInc/Roo-Code/pull/9252",children:"#9252"}),", ",(0,t.jsx)(o.a,{href:"https://github.com/RooCodeInc/Roo-Code/pull/9258",children:"#9258"}),", ",(0,t.jsx)(o.a,{href:"https://github.com/RooCodeInc/Roo-Code/pull/9261",children:"#9261"}),", ",(0,t.jsx)(o.a,{href:"https://github.com/RooCodeInc/Roo-Code/pull/9259",children:"#9259"}),")",(0,t.jsx)(o.br,{}),"\n","Adds the new GPT-5.1 models across supported providers, with extended 24\u2011hour prompt caching support in the OpenAI Native provider and improved overall software\u2011engineering performance."]}),"\n"]}),"\n",(0,t.jsx)(o.h2,{id:"bug-fixes",children:"Bug Fixes"}),"\n",(0,t.jsxs)(o.ul,{children:["\n",(0,t.jsxs)(o.li,{children:["\n",(0,t.jsxs)(o.p,{children:[(0,t.jsx)(o.strong,{children:"Share button works reliably again"})," (",(0,t.jsx)(o.a,{href:"https://github.com/RooCodeInc/Roo-Code/pull/9253",children:"#9253"}),")",(0,t.jsx)(o.br,{}),"\n","Fixes the Share button so you can open the share popover and send shared tasks and messages without failures."]}),"\n"]}),"\n",(0,t.jsxs)(o.li,{children:["\n",(0,t.jsxs)(o.p,{children:[(0,t.jsx)(o.strong,{children:"Keep OpenAI Native reasoning stable during condensing"})," (",(0,t.jsx)(o.a,{href:"https://github.com/RooCodeInc/Roo-Code/pull/9263",children:"#9263"}),")",(0,t.jsx)(o.br,{}),"\n","Keeps encrypted reasoning blocks paired with the assistant messages that produced them so OpenAI Native condensing no longer throws errors and long-running tasks with reasoning stay stable even as history is trimmed."]}),"\n"]}),"\n",(0,t.jsxs)(o.li,{children:["\n",(0,t.jsxs)(o.p,{children:[(0,t.jsx)(o.strong,{children:"Prevent duplicate tool_result blocks for read_file in native protocol"})," (",(0,t.jsx)(o.a,{href:"https://github.com/RooCodeInc/Roo-Code/pull/9272",children:"#9272"}),")",(0,t.jsx)(o.br,{}),"\n","Ensures read_file emits exactly one tool_result per tool_call_id in native protocol, preventing 400 errors while still surfacing clear error messages to both the agent and the user."]}),"\n"]}),"\n",(0,t.jsxs)(o.li,{children:["\n",(0,t.jsxs)(o.p,{children:[(0,t.jsx)(o.strong,{children:'Fix duplicate tool blocks causing "tool has already been used" errors'})," (",(0,t.jsx)(o.a,{href:"https://github.com/RooCodeInc/Roo-Code/pull/9275",children:"#9275"}),")",(0,t.jsx)(o.br,{}),"\n","Stops XML protocol runs from merging duplicate tool blocks into assistant messages so each tool block executes only once per turn and tool-driven tasks no longer get stuck behind false \u201ctool has already been used\u201d errors."]}),"\n"]}),"\n",(0,t.jsxs)(o.li,{children:["\n",(0,t.jsxs)(o.p,{children:[(0,t.jsx)(o.strong,{children:"Make OpenAI Native cancellation stop streaming immediately"})," (",(0,t.jsx)(o.a,{href:"https://github.com/RooCodeInc/Roo-Code/pull/9276",children:"#9276"}),")",(0,t.jsx)(o.br,{}),"\n","Adds an abort controller so cancelling an OpenAI Native request stops streaming promptly, avoiding extra tokens after cancellation and reducing wasted usage."]}),"\n"]}),"\n",(0,t.jsxs)(o.li,{children:["\n",(0,t.jsxs)(o.p,{children:[(0,t.jsx)(o.strong,{children:"Disable XML parser for native tool protocol"})," (",(0,t.jsx)(o.a,{href:"https://github.com/RooCodeInc/Roo-Code/pull/9277",children:"#9277"}),")",(0,t.jsx)(o.br,{}),"\n","Bypasses XML parsing when toolProtocol is set to native and relies on structured tool_call chunks instead, avoiding mis-parsed XML-like snippets and making native tool runs more reliable\u2014especially for models that sometimes mix formats."]}),"\n"]}),"\n"]})]})}function p(e={}){const{wrapper:o}={...(0,r.R)(),...e.components};return o?(0,t.jsx)(o,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},28453(e,o,n){n.d(o,{R:()=>i,x:()=>a});var s=n(96540);const t={},r=s.createContext(t);function i(e){const o=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(o):{...o,...e}},[o,e])}function a(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),s.createElement(r.Provider,{value:o},e.children)}}}]);