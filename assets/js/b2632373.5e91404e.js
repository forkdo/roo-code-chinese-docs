"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[42573],{50512:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>a,contentTitle:()=>d,default:()=>u,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"update-notes/v3.26.5","title":"Roo Code 3.26.5 Release Notes (2025-09-03)","description":"Adds Qwen3 235B Thinking model support, configurable embedding batch size for code indexing, and MCP resource auto-approval.","source":"@site/docs/update-notes/v3.26.5.mdx","sourceDirName":"update-notes","slug":"/update-notes/v3.26.5","permalink":"/update-notes/v3.26.5","draft":false,"unlisted":false,"editUrl":"https://github.com/RooCodeInc/Roo-Code-Docs/edit/main/docs/update-notes/v3.26.5.mdx","tags":[],"version":"current","lastUpdatedAt":1758823095000,"frontMatter":{"description":"Adds Qwen3 235B Thinking model support, configurable embedding batch size for code indexing, and MCP resource auto-approval.","keywords":["roo code 3.26.5","qwen3 thinking model","code indexing batch size","mcp auto-approve"],"image":"/img/v3.26.5/v3.26.5.png"},"sidebar":"tutorialSidebar","previous":{"title":"3.26.6","permalink":"/update-notes/v3.26.6"},"next":{"title":"3.26.4","permalink":"/update-notes/v3.26.4"}}');var i=o(74848),s=o(28453);const r={description:"Adds Qwen3 235B Thinking model support, configurable embedding batch size for code indexing, and MCP resource auto-approval.",keywords:["roo code 3.26.5","qwen3 thinking model","code indexing batch size","mcp auto-approve"],image:"/img/v3.26.5/v3.26.5.png"},d="Roo Code 3.26.5 Release Notes (2025-09-03)",a={},c=[{value:"Provider Updates",id:"provider-updates",level:2},{value:"QOL Improvements",id:"qol-improvements",level:2},{value:"Bug Fixes",id:"bug-fixes",level:2}];function l(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"roo-code-3265-release-notes-2025-09-03",children:"Roo Code 3.26.5 Release Notes (2025-09-03)"})}),"\n",(0,i.jsx)(n.p,{children:"This release adds support for the Qwen3 235B Thinking model with a 262K context window, introduces configurable embedding batch sizes for code indexing, and improves MCP resource auto-approval."}),"\n",(0,i.jsx)("img",{src:"/img/v3.26.5/v3.26.5.png",alt:"Roo Code v3.26.5 Release",width:"600"}),"\n",(0,i.jsx)(n.h2,{id:"provider-updates",children:"Provider Updates"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Qwen3 235B Thinking Model"}),": Added support for Qwen3-235B-A22B-Thinking-2507 model with an impressive 262K context window, enabling processing of extremely long documents and large codebases in a single request through the Chutes provider (thanks mohammad154, apple-techie!) (",(0,i.jsx)(n.a,{href:"https://github.com/RooCodeInc/Roo-Code/pull/7578",children:"#7578"}),")"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"qol-improvements",children:"QOL Improvements"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"MCP Resource Auto-Approval"}),": MCP resource access requests are now automatically approved when auto-approve is enabled, eliminating manual approval steps and enabling smoother automation workflows (thanks m-ibm!) (",(0,i.jsx)(n.a,{href:"https://github.com/RooCodeInc/Roo-Code/pull/7606",children:"#7606"}),")"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Message Queue Performance"}),": Improved message queueing reliability and performance by moving the queue management to the extension host, making the interface more stable (",(0,i.jsx)(n.a,{href:"https://github.com/RooCodeInc/Roo-Code/pull/7604",children:"#7604"}),")"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"bug-fixes",children:"Bug Fixes"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Configurable Embedding Batch Size"}),": Fixed an issue where users with API providers having stricter batch limits couldn't use code indexing. You can now configure the embedding batch size (1-2048, default: 400) to match your provider's limits (thanks BenLampson!) (",(0,i.jsx)(n.a,{href:"https://github.com/RooCodeInc/Roo-Code/pull/7464",children:"#7464"}),")"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"OpenAI-Native Cache Reporting"}),": Fixed cache usage statistics and cost calculations when using the OpenAI-Native provider with cached content (",(0,i.jsx)(n.a,{href:"https://github.com/RooCodeInc/Roo-Code/pull/7602",children:"#7602"}),")"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},28453:(e,n,o)=>{o.d(n,{R:()=>r,x:()=>d});var t=o(96540);const i={},s=t.createContext(i);function r(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);