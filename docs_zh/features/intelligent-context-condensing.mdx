---
description: 了解智能上下文压缩功能如何通过总结早期对话来管理长对话，防止在接近上下文限制时丢失重要信息。
keywords:
  - 上下文压缩
  - 上下文窗口
  - 对话管理
  - Token 优化
  - AI 摘要
image: /img/social-share.jpg
sidebar_label: '智能上下文压缩'
---
import Codicon from '@site/src/components/Codicon';

# 智能上下文压缩

智能上下文压缩功能通过总结对话的早期部分来帮助管理长对话，防止在上下文窗口接近限制时丢失重要信息。此功能**默认启用**。

<div style={{ position: 'relative', paddingBottom: '56.25%', height: 0, overflow: 'hidden' }}>
  <iframe
    src="https://www.youtube.com/embed/9k8OAXlszak"
    style={{
      position: 'absolute',
      top: 0,
      left: 0,
      width: '100%',
      height: '100%',
    }}
    frameBorder="0"
    allow="autoplay; encrypted-media"
    allowFullScreen
  ></iframe>
</div>

<br />
---

## 工作原理

当您与 Roo Code 的对话增长时，可能会接近底层 AI 模型的上下文窗口限制。发生这种情况时，旧消息通常会被删除以腾出空间。智能上下文压缩旨在通过以下方式防止这种突然的信息丢失：

1.  **摘要化**：使用 AI 模型压缩对话的早期部分。
2.  **保留核心信息**：目标是在减少整体 Token 数量的同时保留摘要消息中的关键信息。
3.  **保持流程连贯**：这使得 AI 能够更连贯地理解整个对话，即使是极长的对话。
4.  **保护首条消息**：包含斜杠命令或初始上下文的首条消息在压缩过程中始终被保留，确保关键的初始指令不会丢失。

**重要注意事项：**
*   **摘要化影响**：如果您使用 [检查点](/features/checkpoints) 回溯，原始消息会被保留，但摘要版本会用于正在进行的 LLM 调用，以保持上下文的可管理性。
*   **成本**：执行摘要化的 AI 调用会产生费用。此费用包含在 UI 中显示的上下文压缩指标中。
*   **首条消息保护**：包含斜杠命令或设置指令的初始消息永远不会被压缩。

---

## 配置

智能上下文压缩功能**默认启用**，并提供多种配置选项：

1.  打开 Roo Code 设置（Roo Code 面板右上角的 <Codicon name="gear" /> 图标）。
2.  导航到"上下文"设置部分以配置上下文相关选项，或导航到"提示"设置部分以配置自定义提示。
3.  配置可用选项：
    - **自动触发智能上下文压缩**：默认启用，控制压缩是否自动发生（在"上下文"设置中找到）
    - **触发智能上下文压缩的阈值**：百分比滑块（默认 100%），根据上下文窗口使用率确定压缩何时激活（在"上下文"设置中找到）
    - **上下文压缩的 API 配置**：选择用于压缩操作的 API 配置（默认为当前活动配置）（在"上下文"设置中找到）
    - **自定义上下文压缩提示**：自定义用于上下文压缩操作的系统提示（在"提示"设置中找到）

<img src="/img/intelligent-context-condensing/intelligent-context-condensing.png" alt="智能上下文压缩的设置" width="600" />
*智能上下文压缩配置选项：自动触发切换、阈值滑块、API 配置选择和自定义提示定制。*
---

## 控制和理解上下文压缩

Roo Code 提供了多种方式来控制和理解智能上下文压缩功能：

### 控制上下文压缩
*   **自动阈值**："上下文"设置中的阈值滑块允许您定义上下文窗口使用率的百分比（例如 80%）。当对话达到此容量水平时，Roo Code 将尝试压缩上下文。
*   **API 配置**：选择用于上下文压缩操作的 API 配置。如果您需要，可以使用不同的提供商或模型专门进行压缩。
*   **自定义提示**：修改用于压缩的系统提示，以更好地适应您的工作流程或强调对话摘要的某些方面。
*   **手动触发**：任务顶部提供了一个**压缩上下文**按钮，位于上下文栏右侧。这允许您随时启动上下文压缩过程。

    <img src="/img/intelligent-context-condensing/intelligent-context-condensing-1.png" alt="展开任务视图中的手动压缩上下文按钮" width="600" />
    *手动压缩上下文按钮（黄色箭头突出显示）易于访问，便于手动控制。*

### 理解上下文压缩活动
*   **上下文压缩指标**：当上下文压缩发生时，Roo Code 显示：
    *   压缩前后的上下文 Token 计数。
    *   与上下文压缩 AI 调用相关的成本。
    *   可展开的摘要，详细说明被压缩的内容（此信息是聊天历史中可见的 `ContextCondenseRow` 组件的一部分）。

<img src="/img/intelligent-context-condensing/intelligent-context-condensing-2.png" alt="聊天中的上下文压缩消息" width="600" />
*上下文压缩后，消息指示上下文已被压缩，显示 Token 变化和成本。*

*   **视觉指示器**：
    *   在聊天界面中，上下文压缩活动期间会显示进度指示器（"正在压缩上下文..."）。

<img src="/img/intelligent-context-condensation/intelligent-context-condensation-3.png" alt="聊天中的压缩上下文进度指示器" width="600" />
*"正在压缩上下文..." 指示器在过程中出现在聊天中。*

    *   任务标题还显示当前上下文压缩状态。
    *   `ContextWindowProgress` 条提供了 Token 分布的可视化表示，包括当前使用量、为 AI 输出保留的空间、可用空间和原始 Token 数量。
*   **界面清晰度**："压缩上下文"按钮包含一个工具提示，解释其功能，支持所有语言。

---

## 有效上下文压缩的技巧

### 自定义上下文压缩提示

您可以自定义上下文压缩提示，以更好地适应您的特定领域或用例。如果您发现默认压缩过程丢失了对您工作流程重要的特定信息，这特别有用。

自定义提示的方法：
1. 进入 Roo Code 设置（<Codicon name="gear" /> 图标）
2. 导航到"提示"设置部分
3. 在下拉菜单中找到"自定义上下文压缩提示"
4. 输入您的自定义提示，指导 AI 如何保留特定类型的信息

例如，如果您正在进行复杂的调试会话，您可能会添加如下指令：
- "始终完整保留错误消息和堆栈跟踪"
- "维护所有变量名及其最后已知值"
- "跟踪所有尝试的解决方案及其结果"

这种自定义确保上下文压缩过程保留对您特定用例最关键的信息。

---

## 自动错误恢复

当 Roo Code 遇到上下文窗口限制错误时，现在会自动恢复以保持您的工作流程：

### 错误恢复的工作原理

1. **错误检测**：Roo Code 检测来自多个提供商的上下文窗口错误（OpenAI、Anthropic、Cerebras 等）
2. **自动截断**：系统自动将上下文减少 25%
3. **重试机制**：截断后，Roo Code 重试您的请求（最多 3 次尝试）
4. **无缝继续**：您的工作无需手动干预即可继续

这种自动恢复确保：
- 您不会因上下文限制错误而丢失工作
- 长对话可以顺利继续
- 系统智能地管理上下文，无需手动重启

### 触发恢复的时机

自动恢复在以下情况下激活：
- API 返回上下文窗口超出错误
- 对话接近最大 Token 限制
- 多个提供商报告类似的上下文相关错误

此功能与智能上下文压缩配合使用，提供多层上下文管理，确保您的对话即使在具有挑战性的情况下也能继续。

---

## 技术实现

### Token 计数
Roo Code 使用复杂的 Token 计数系统，该系统：
- 在可用时采用原生 Token 计数端点（例如 Anthropic 的 API）
- 如果 API 调用失败，则回退到 tiktoken 估算
- 为不同类型的内容提供准确的计数：
  - 文本内容：使用基于单词的估算，包含标点符号和换行符开销
  - 图像内容：使用每张图像 300 个 Token 的保守估算
  - 系统提示：包括结构元素的额外开销

### 上下文窗口管理
- 默认情况下，上下文窗口的 30% 被保留（20% 用于模型输出，10% 作为安全缓冲区），剩余 70% 可用于对话历史。
- 此保留可以通过模型特定设置覆盖
- 系统在保持此保留的同时自动计算可用空间

### 错误处理策略
- **多提供商支持**：识别来自 OpenAI、Anthropic、Cerebras 和其他提供商的上下文错误
- **渐进式减少**：每次重试尝试时将上下文减少 25%
- **重试限制**：最多 3 次自动重试尝试，之后需要手动干预
- **状态保持**：在恢复尝试期间保持对话状态